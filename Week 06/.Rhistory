result
1-mean(result)
sd(result)
result <- vector(length = TRY)
for(i in 1:TRY){
train <- get_N(TRAINN)
svmfit<-svm(y~.,data=train,cost=10,scale=FALSE)
test <- get_N(TESTN)
predicted <- predict(svmfit, newdata=test)
result[i] <-  sum(ifelse(predicted > 0.5,1,0) == test$y) / TESTN
}
1-mean(result)
sd(result)
result <- vector(length = TRY)
for(i in 1:TRY){
train <- get_N(TRAINN)
svmfit<-svm(y~.,data=train)
test <- get_N(TESTN)
predicted <- predict(svmfit, newdata=test)
result[i] <-  sum(ifelse(predicted > 0.5,1,0) == test$y) / TESTN
}
1-mean(result)
sd(result)
result <- vector(length = TRY)
for(i in 1:TRY){
train <- get_N(TRAINN)
svmfit<-svm(y~.,data=train)
test <- get_N(TESTN)
predicted <- predict(svmfit, kernel=linear, newdata=test)
result[i] <-  sum(ifelse(predicted > 0.5,1,0) == test$y) / TESTN
}
1-mean(result)
sd(result)
?gbm
library gbm
library(gbm)
library gbm
?gbm
TRY <- 100
TESTN <- 10000
TRAINN <- 100
?glm
result <- vector(length = TRY)
for(i in 1:TRY){
train <- get_N(TRAINN)
--  ffit<-svm(y~.,data=train)
ffit <- glm(y~.,data=train, family=binomial)
test <- get_N(TESTN)
predicted <- predict(ffit, newdata=test)
result[i] <-  sum(ifelse(predicted > 0.5,1,0) == test$y) / TESTN
}
1-mean(result)
sd(result)
train <- get_N(TRAINN)
ffit <- glm(y~.,data=train, family=binomial)
summary(ffit)
testmy = test[-y,]
testmy = test[-1,]
head (testmy)
testmy <- test[,-y]
testmy <- test[,-1]
head testmy
head(testmy)
testmy = test[,-1]
predicted <- predict(ffit, newdata=test)
predicted
sum(ifelse(predicted > 0.5,1,0)
)
result <- vector(length = TRY)
for(i in 1:TRY){
train <- get_N(TRAINN)
--  ffit<-svm(y~.,data=train)
ffit <- glm(y~.,data=train, family=binomial)
test <- get_N(TESTN)
testmy = test[,-1]
predicted <- predict(ffit, newdata=test)
result[i] <-  sum(ifelse(predicted > 0.5,1,0) == test$y) / TESTN
}
1-mean(result)
sd(result)
result
predicted
sum(ifelse(predicted > 0.5,1,0) == test$y)
TRY <- 100
TESTN <- 10000
TRAINN <- 100
result <- vector(length = TRY)
for(i in 1:TRY){
train <- get_N(TRAINN)
--  ffit<-svm(y~.,data=train)
ffit <- glm(y~.,data=train, family=binomial)
test <- get_N(TESTN)
testmy = test[,-1]
predicted <- predict(ffit, newdata=test)
result[i] <-  sum(ifelse(predicted > 0.5,1,0) == test$y) / TESTN
}
1-mean(result)
sd(result)
result <- vector(length = TRY)
for(i in 1:TRY){
train <- get_N(TRAINN)
--  ffit<-svm(y~.,data=train)
ffit <- glm(y~.,data=train, family=binomial)
test <- get_N(TESTN)
testmy = test[,-1]
predicted <- predict(ffit, newdata=testmy)
result[i] <-  sum(ifelse(predicted > 0.5,1,0) == test$y) / TESTN
}
1-mean(result)
sd(result)
result
sum(ifelse(predicted > 0.5,1,0) == test$y) / TESTN
sum(ifelse(predicted > 0.5,1,0) = test$y) / TESTN
result <- array(1:TRY)
for(i in 1:TRY){
train <- get_N(TRAINN)
--  ffit<-svm(y~.,data=train)
ffit <- glm(y~.,data=train, family=binomial)
test <- get_N(TESTN)
testmy = test[,-1]
predicted <- predict(ffit, newdata=testmy)
result[i] <-  sum(ifelse(predicted > 0.5,1,0) == test$y) / TESTN
}
1-mean(result)
sd(result)
result
result <- array(TRY)
result
a[1] <- 1
a <- array()
a[1] <- 1
a
result <- array()
for(i in 1:TRY){
train <- get_N(TRAINN)
--  ffit<-svm(y~.,data=train)
ffit <- glm(y~.,data=train, family=binomial)
test <- get_N(TESTN)
testmy = test[,-1]
predicted <- predict(ffit, newdata=testmy)
result[i] <-  sum(ifelse(predicted > 0.5,1,0) == test$y) / TESTN
}
train <- get_N(TRAINN)
--  ffit<-svm(y~.,data=train)
ffit <- glm(y~.,data=train, family=binomial)
ffit <- glm(y~.,data=train, family=binomial())
result <- array()
for(i in 1:TRY){
train <- get_N(TRAINN)
--  ffit<-svm(y~.,data=train)
ffit <- glm(y~.,data=train, family=binomial())
test <- get_N(TESTN)
testmy = test[,-1]
predicted <- predict(ffit, newdata=testmy)
result[i] <-  sum(ifelse(predicted > 0.5,1,0) == test$y) / TESTN
}
train <- get_N(TRAINN)
--  ffit<-svm(y~.,data=train)
ffit <- glm(y~.,data=train, family=binomial
result <- array()
for(i in 1:TRY){
train <- get_N(TRAINN)
#  ffit<-svm(y~.,data=train)
ffit <- glm(y~.,data=train, family=binomial)
test <- get_N(TESTN)
testmy = test[,-1]
predicted <- predict(ffit, newdata=testmy)
result[i] <-  sum(ifelse(predicted > 0.5,1,0) == test$y) / TESTN
}
1-mean(result)
sd(result)
dimnames(USArrests)
apply(USArrests,2,mean)
apply(USArrests,2, var)
pca.out=prcomp(USArrests, scale=TRUE)
pca.out
names(pca.out)
biplot(pca.out, scale=0)
set.seed(101)
x=matrix(rnorm(100*2),100,2)
xmean=matrix(rnorm(8,sd=4),4,2)
which=sample(1:4,100,replace=TRUE)
x=x+xmean[which,]
plot(x,col=which,pch=19)
km.out=kmeans(x,4,nstart=15)
km.out
plot(x,col=km.out$cluster,cex=2,pch=1,lwd=2)
points(x,col=which,pch=19)
points(x,col=c(4,3,2,1)[which],pch=19)
file <- "C:\\Users\\mmorelli\\Google Drive\\Statistical Learning Stanford\\Week10\\10.R.RData"
load(file)
file <- "C:\\Users\\mmorelli\\Google Drive\\Statistical Learning Stanford\\Week10\\10.R.RData"
load(file)
head(x)
pca.out=prcomp(x, scale=TRUE)
tot <- rbind(x, x.test)
pca.out=prcomp(tot, scale=TRUE)
names(x)
names(x.test)
dimnames(USArrests)
apply(USArrests,2,mean)
apply(USArrests,2, var)
pca.out=prcomp(USArrests, scale=TRUE)
pca.out
names(pca.out)
biplot(pca.out, scale=0)
pca.out=prcomp(tot, scale=TRUE)
?prcomp
pca.out$sdev
pca.out$rotation
pca.out$x
summary(pca.out)
redux <- pca.out$x[1,c(1,5)]
head(redux)
redux <- pca.out$x[1,c(1,5)]
head(redux)
pca.out$sdev
str(pca.out)
str(pca.out)$x
str(pca.out)$x
redux <- pca.out$x[1,c(1,5)]
pca.5 <- pca.out$x[1,c(1,5)]
pca.5 <- pca.out$x[1,c(1:5)]
redux
pca.5 <- pca.out$x[,c(1:5)]
head(pca.5)
pca.5 <- as_data_frame(pca.out$x[,c(1:5)])
pca.5 <- as.data.frame(pca.out$x[,c(1:5)])
reconstructedData<-predict(pca.out, x)
x.pca <-predict(pca.out, x)
head x.pca
x.pca <-predict(pca.out, x)
head(x.pca)
x.pca <-predict(pca.out, x)[,c(1:5)]
head(x.pca)
xy.pca <- cbind(x.pca, y)
head(xy.pca)
fit <- lm(y~., data=xy.pca)
xy.pca <- as.data.frame(cbind(x.pca, y))
head(xy.pca)
fit <- lm(y~., data=xy.pca)
summary(fit)
summary(fit)
x.test.pca  <- predict(pca.out, x.test)[,c(1:5)]
xy.test.pca <- as.data.frame(cbind(x.test.pca, y.test))
y.pred <- predict(fit, xy.test.pca)
se <- (y.pred- y.test)^2
sum(se)/1000
mean(se)
train <- as.data.frame(cbind(x, y))
train <- as.data.frame(cbind(x, y))
test  <- as.data.frame(cbind(x.test, y.test))
fit.all <- lm(y~., train)
y.all.pred <- predict(fit.all, test)
se.all <- (y.all.pred -y.test)^2
mean(se.all)
load(file)
train <- as.data.frame(cbind(x, y))
test  <- as.data.frame(cbind(x.test, y.test))
fit.all <- lm(y~., train)
y.all.pred <- predict(fit.all, test)
se.all <- (y.all.pred -y.test)^2
mean(se.all)
file <- "C:\\Users\\mmorelli\\Google Drive\\Statistical Learning Stanford\\Week10\\10.R.RData"
load(file)
train <- as.data.frame(cbind(x, y))
test  <- as.data.frame(cbind(x.test, y.test))
fit.all <- lm(y~., train)
y.all.pred <- predict(fit.all, test)
se.all <- (y.all.pred -y.test)^2
mean(se.all)
?lm
fit.all
summary(fit.all)
mean(se.all)
file <- "C:\\Users\\mmorelli\\Documents\\work\\Campagne\\10.R.RData\\campagne.csv"
camp <- load.csv(file)
?load
camp <- read.csv(file)
file <- "C:\\Users\\mmorelli\\Documents\\work\\Campagne\\campagne.csv"
camp <- read.csv(file)
head(camp)
names(camp)
?read.csv
camp <- read.csv(file, sep=";")
head(camp)
names(camp)
unique(Subject)
unique(camp$Subject)
names(camp)
unique(camp$Email.Template.Name)
camp[leistung$Email.Template.Name %in% c("2016-01 Contacts Compliance", "2016-01 Mailing Compliance", "2016-01 Leads Compliance"),]$template <- "Compliance"
camp[leistung$Email.Template.Name %in% c("2016-01 Contacts Schadensvermeidung", "2016-01 Leads Schadensvermeidung", "2016-01 Mailing Schadensvermeidung"),]$template <- "Schadensverm."
camp[leistung$Email.Template.Name %in% c("2016-01 Contacts Zeitoptimierung", "2016-01 Mailing Zeitoptimierung", "2016-01 Leads Zeitoptimierung"),]$template <- "Zeitoptim"
camp[leistung$Email.Template.Name %in% c("2016-01 Contacts _berblick", "2016-01 Mailing _berblick", "2016-01 Leads _berblick"),]$template <- ""
camp[leistung$Email.Template.Name %in% c("2016-01 Contacts Planungssicherheit", "2016-01 Mailing Planungssicherheit", "2016-01 Leads Planungssicherheit"),]$template <- ""
camp[camp$Email.Template.Name %in% c("2016-01 Contacts Compliance", "2016-01 Mailing Compliance", "2016-01 Leads Compliance"),]$template <- "Compliance"
camp[camp$Email.Template.Name %in% c("2016-01 Contacts Compliance", "2016-01 Mailing Compliance", "2016-01 Leads Compliance"),]
names(camp)
histogram(camp$OpenedNum)
library(ggplot2)
m <- ggplot(camp, aes(x=OpenedNum))
m + geom_histogram()
str(camp)
m <- ggplot(camp, aes(x=X..Times.Opened))
m + geom_histogram()
m <- ggplot(camp, aes(x=Pattern))
m + geom_histogram()
m <- ggplot(camp, aes(x=X..Times.Opened))
m + geom_histogram()
tail(camp)
camp[is.na(camp[,"Count"]),]
camp[!is.na(camp[,"Count"]),]
camp <- camp[!is.na(camp[,"Count"]),]
m <- ggplot(camp, aes(x=X..Times.Opened))
m + geom_histogram()
?table
names(camp)
table(camp$X..Times.Opened, camp$Type)
table(camp$X..Times.Opened)
table(camp$X..Times.Opened, camp$Type)
names(camp)
table(camp$Wann.Gen, camp$Type)
table(camp[camp$Genervt == 1,]$Wann.Gen, camp[camp$Genervt == 1,]$$Type)
table(camp[camp$Genervt == 1,]$Wann.Gen, camp[camp$Genervt == 1,]$Type)
head(camp)
str(camp)
m <- ggplot(camp, aes(x=X..Times.Opened)) + geom_histogram()
m
table(camp[camp$Genervt == "Ok",]$Wann.Gen, camp[camp$Genervt == "Ok",]$Type)
table(camp[camp$Genervt == "Gen",]$Wann.Gen, camp[camp$Genervt == "Gen",]$Type)
table(camp[camp$Genervt == "Ok",]$Rehienfolge, camp[camp$Genervt == "Ok",]$Type)
str(camp)
table(camp[camp$Genervt == "Ok",]$Rehienfolge, camp[camp$Genervt == "Ok",]$Type)
camp[camp$Genervt == "Ok",]$Rehienfolge
camp[camp$Genervt == "Ok",]$Rehienfolge
camp$Genervt
camp$Genervt == "Ok"
camp[camp$Genervt == "Ok",]
table(camp[camp$Genervt == "Ok",]$Reihenfolge, camp[camp$Genervt == "Ok",]$Type)
file <- "C:\\Users\\mmorelli\\Google Drive\\Statistical Learning Stanford\\Week10\\10.R.RData"
load(file)
head(x)
tot <- rbind(x, x.test)
pca.out=prcomp(tot, scale=TRUE)
pca.out$sdev
redux <- pca.out$x[1,c(1,5)]
dim(redux)
summary(redux)
dimension(redux)
str(redux)
dim.data.frame(redux)
length(redux)
nrow(redux)
redux
redux <- pca.out$x[,c(1,5)]
redux <- pca.out$x[,c(1,5)]
dim(redux)
file <- "C:\\Users\\mmorelli\\Google Drive\\Statistical Learning Stanford\\Week10\\10.R.RData"
load(file)
head(x)
tot <- rbind(x, x.test)
pca.out=prcomp(tot, scale=TRUE)
pca.out$sdev
redux <- pca.out$x[,c(1,5)]
dim(redux)
x.pca  <-predict(pca.out, x)[,c(1:5)]
file <- "C:\\Users\\mmorelli\\Google Drive\\Statistical Learning Stanford\\Week10\\10.R.RData"
load(file)
tot <- rbind(x, x.test)
pca.out=prcomp(tot, scale=TRUE)
file <- "C:\\Users\\mmorelli\\Google Drive\\Statistical Learning Stanford\\Week10\\10.R.RData"
load(file)
tot <- rbind(x, x.test)
pca.out=prcomp(tot, scale=TRUE)
pca.out$sdev
x.pca  <-predict(pca.out, x)[,c(1:5)]
Group<-c(rep("Frank",times=6),rep("Greg",times=11),rep("Stacy",times=3),rep("Nancy",times=10))
X<-c(4,5,3,5,7,4,8,23,4,7,5,2,8,5,8,3,6,5,4,6,8,9,2,5,8,3,6,3,3,4)
Y<-c(7,9,3,6,4,8,7,8,6,3,2,3,6,7,4,6,8,9,5,7,8,9,6,5,4,6,7,8,3,6)
df<-data.frame(Group,as.numeric(X),as.numeric(Y))
Group
df
library(geometry)
install.package(geometry)
install.packages("geometry")
library(geometry)
convhulln(Frank.frame, option="FA")$vol
Frank.frame<-cbind(df$X[df$Group=="Frank"],df$Y[df$Group=="Frank"])
convhulln(Frank.frame, option="FA")$vol
setwd("C:\\Users\\mmorelli\\Google Drive\\MITx 15 071x The Analytics Edge\\Week 06")
Sys.setlocale("LC_ALL", "C")
setwd("C:\\Users\\mmorelli\\Google Drive\\MITx 15 071x The Analytics Edge\\Week 06")
Sys.setlocale("LC_ALL", "C")
airlines <- read.csv("AirlinesCluster.csv")
summary(airlines)
stocks <- read.csv("StocksCluster.csv")
mean(stocks$PositiveDec)
f <- c("ReturnJan", "ReturnFeb", "ReturnMar", "ReturnApr", "ReturnMay", "ReturnJune", "ReturnJuly", "ReturnAug", "ReturnSep", "ReturnOct", "ReturnNov")
cor(stocks[,f])
summary(stocks)
library(caTools)
set.seed(144)
spl = sample.split(stocks$PositiveDec, SplitRatio = 0.7)
stocksTrain = subset(stocks, spl == TRUE)
stocksTest  = subset(stocks, spl == FALSE)
## logistic regression
StocksModel <- glm(stocksTrain$PositiveDec ~ ., data=stocksTrain, family=binomial)
pred <- predict(StocksModel, type="response")
table(stocksTrain$PositiveDec, pred >= 0.5)
(990+3640)/nrow(stocksTrain)
pred.test <- predict(StocksModel, newdata=stocksTest, type="response")
table(stocksTest$PositiveDec, pred.test >= 0.5)
(417+1553)/nrow(stocksTest)
table(stocksTest$PositiveDec)
1897/nrow(stocksTest)
# Problem 3.1 - Clustering Stocks
limitedTrain = stocksTrain
limitedTrain$PositiveDec = NULL
limitedTest = stocksTest
limitedTest$PositiveDec = NULL
# pre process
library(caret)
preproc = preProcess(limitedTrain)
normTrain = predict(preproc, limitedTrain)
normTest = predict(preproc, limitedTest)
mean(normTrain$ReturnJan)
mean(normTest$ReturnJan)
#Problem 3.4 - Clustering Stocks
set.seed(144)
km = kmeans(normTrain, centers = 3)
str(km)
table(km$cluster)
library(flexclust)
km.kcca = as.kcca(km, normTrain)
clusterTrain = predict(km.kcca)
clusterTest = predict(km.kcca, newdata=normTest)
table(clusterTest)
# Problem 4.1 - Cluster-Specific Predictions
stocksTrain1 <- stocksTrain[km$cluster==1,]
stocksTrain2 <- stocksTrain[km$cluster==2,]
stocksTrain3 <- stocksTrain[km$cluster==3,]
mean(stocksTrain1$PositiveDec)
mean(stocksTrain2$PositiveDec)
mean(stocksTrain3$PositiveDec)
# Problem 4.2 - Cluster-Specific Predictions
StocksModel1 <- glm(stocksTrain1$PositiveDec ~ ., data=stocksTrain1, family=binomial)
StocksModel2 <- glm(stocksTrain2$PositiveDec ~ ., data=stocksTrain2, family=binomial)
StocksModel3 <- glm(stocksTrain3$PositiveDec ~ ., data=stocksTrain3, family=binomial)
StocksModel1$coefficients
StocksModel1$coefficients
#pred <- predict(StocksModel, type="response")
StocksModel1$coefficients
StocksModel1$coefficients
StocksModel2$coefficients
StocksModel1$coefficients
StocksModel2$coefficients
StocksModel3$coefficients
pred.test1 <- predict(StocksModel1, newdata=stocksTest1, type="response")
stocksTest1 <- stocksTest[km$cluster==1,]
stocksTest2 <- stocksTest[km$cluster==2,]
stocksTest3 <- stocksTest[km$cluster==3,]
pred.test1 <- predict(StocksModel1, newdata=stocksTest1, type="response")
table(stocksTest1$PositiveDec, pred.test1 >= 0.5)
(101+498)/nrow(stocksTest1)
nrow(stocksTest1)
StocksModel1
stocksTest1
nrow(stocksTest1)
table(stocksTest1$PositiveDec, pred.test1 >= 0.5)
pred.test1
stocksTest1
clusterTrain
stocksTrain1 <- stocksTrain[clusterTrain==1,]
stocksTrain2 <- stocksTrain[clusterTrain==2,]
stocksTrain3 <- stocksTrain[clusterTrain==3,]
stocksTrain1
mean(stocksTrain1$PositiveDec)
mean(stocksTrain2$PositiveDec)
mean(stocksTrain3$PositiveDec)
stocksTest1 <- stocksTest[clusterTest==1,]
stocksTest2 <- stocksTest[clusterTest==2,]
stocksTest3 <- stocksTest[clusterTest==3,]
# Problem 4.2 - Cluster-Specific Predictions
StocksModel1 <- glm(stocksTrain1$PositiveDec ~ ., data=stocksTrain1, family=binomial)
StocksModel2 <- glm(stocksTrain2$PositiveDec ~ ., data=stocksTrain2, family=binomial)
StocksModel3 <- glm(stocksTrain3$PositiveDec ~ ., data=stocksTrain3, family=binomial)
StocksModel1$coefficients
StocksModel2$coefficients
StocksModel3$coefficients
pred.test1 <- predict(StocksModel1, newdata=stocksTest1, type="response")
table(stocksTest1$PositiveDec, pred.test1 >= 0.5)
(30+774)/nrow(stocksTest1)
pred.test2 <- predict(StocksModel2, newdata=stocksTest2, type="response")
table(stocksTest2$PositiveDec, pred.test2 >= 0.5)
(388+ 757)/nrow(stocksTest2)
pred.test3 <- predict(StocksModel2, newdata=stocksTest3, type="response")
table(stocksTest3$PositiveDec, pred.test3 >= 0.5)
(7+33)/nrow(stocksTest3)
pred.test3 <- predict(StocksModel3, newdata=stocksTest3, type="response")
table(stocksTest3$PositiveDec, pred.test3 >= 0.5)
(49+13)/nrow(stocksTest3)
(30+774)/nrow(stocksTest1)
(30+774)/nrow(stocksTest1)
(388+ 757)/nrow(stocksTest2)
(49+13)/nrow(stocksTest3)
AllPredictions = c(PredictTest1, PredictTest2, PredictTest3)
AllPredictions = c(pred.test1, pred.test2, pred.test3)
AllOutcomes = c(stocksTest1$PositiveDec, stocksTest2$PositiveDec, stocksTest3$PositiveDec)
table(AllOutcomes, AllPredictions)
table(AllOutcomes, AllPredictions >=0.5)
(467+1544)/length(AllPredictions)
