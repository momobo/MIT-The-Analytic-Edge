redux <- pca.out$x[1,c(1,5)]
pca.5 <- pca.out$x[1,c(1,5)]
pca.5 <- pca.out$x[1,c(1:5)]
redux
pca.5 <- pca.out$x[,c(1:5)]
head(pca.5)
pca.5 <- as_data_frame(pca.out$x[,c(1:5)])
pca.5 <- as.data.frame(pca.out$x[,c(1:5)])
reconstructedData<-predict(pca.out, x)
x.pca <-predict(pca.out, x)
head x.pca
x.pca <-predict(pca.out, x)
head(x.pca)
x.pca <-predict(pca.out, x)[,c(1:5)]
head(x.pca)
xy.pca <- cbind(x.pca, y)
head(xy.pca)
fit <- lm(y~., data=xy.pca)
xy.pca <- as.data.frame(cbind(x.pca, y))
head(xy.pca)
fit <- lm(y~., data=xy.pca)
summary(fit)
summary(fit)
x.test.pca  <- predict(pca.out, x.test)[,c(1:5)]
xy.test.pca <- as.data.frame(cbind(x.test.pca, y.test))
y.pred <- predict(fit, xy.test.pca)
se <- (y.pred- y.test)^2
sum(se)/1000
mean(se)
train <- as.data.frame(cbind(x, y))
train <- as.data.frame(cbind(x, y))
test  <- as.data.frame(cbind(x.test, y.test))
fit.all <- lm(y~., train)
y.all.pred <- predict(fit.all, test)
se.all <- (y.all.pred -y.test)^2
mean(se.all)
load(file)
train <- as.data.frame(cbind(x, y))
test  <- as.data.frame(cbind(x.test, y.test))
fit.all <- lm(y~., train)
y.all.pred <- predict(fit.all, test)
se.all <- (y.all.pred -y.test)^2
mean(se.all)
file <- "C:\\Users\\mmorelli\\Google Drive\\Statistical Learning Stanford\\Week10\\10.R.RData"
load(file)
train <- as.data.frame(cbind(x, y))
test  <- as.data.frame(cbind(x.test, y.test))
fit.all <- lm(y~., train)
y.all.pred <- predict(fit.all, test)
se.all <- (y.all.pred -y.test)^2
mean(se.all)
?lm
fit.all
summary(fit.all)
mean(se.all)
file <- "C:\\Users\\mmorelli\\Documents\\work\\Campagne\\10.R.RData\\campagne.csv"
camp <- load.csv(file)
?load
camp <- read.csv(file)
file <- "C:\\Users\\mmorelli\\Documents\\work\\Campagne\\campagne.csv"
camp <- read.csv(file)
head(camp)
names(camp)
?read.csv
camp <- read.csv(file, sep=";")
head(camp)
names(camp)
unique(Subject)
unique(camp$Subject)
names(camp)
unique(camp$Email.Template.Name)
camp[leistung$Email.Template.Name %in% c("2016-01 Contacts Compliance", "2016-01 Mailing Compliance", "2016-01 Leads Compliance"),]$template <- "Compliance"
camp[leistung$Email.Template.Name %in% c("2016-01 Contacts Schadensvermeidung", "2016-01 Leads Schadensvermeidung", "2016-01 Mailing Schadensvermeidung"),]$template <- "Schadensverm."
camp[leistung$Email.Template.Name %in% c("2016-01 Contacts Zeitoptimierung", "2016-01 Mailing Zeitoptimierung", "2016-01 Leads Zeitoptimierung"),]$template <- "Zeitoptim"
camp[leistung$Email.Template.Name %in% c("2016-01 Contacts _berblick", "2016-01 Mailing _berblick", "2016-01 Leads _berblick"),]$template <- ""
camp[leistung$Email.Template.Name %in% c("2016-01 Contacts Planungssicherheit", "2016-01 Mailing Planungssicherheit", "2016-01 Leads Planungssicherheit"),]$template <- ""
camp[camp$Email.Template.Name %in% c("2016-01 Contacts Compliance", "2016-01 Mailing Compliance", "2016-01 Leads Compliance"),]$template <- "Compliance"
camp[camp$Email.Template.Name %in% c("2016-01 Contacts Compliance", "2016-01 Mailing Compliance", "2016-01 Leads Compliance"),]
names(camp)
histogram(camp$OpenedNum)
library(ggplot2)
m <- ggplot(camp, aes(x=OpenedNum))
m + geom_histogram()
str(camp)
m <- ggplot(camp, aes(x=X..Times.Opened))
m + geom_histogram()
m <- ggplot(camp, aes(x=Pattern))
m + geom_histogram()
m <- ggplot(camp, aes(x=X..Times.Opened))
m + geom_histogram()
tail(camp)
camp[is.na(camp[,"Count"]),]
camp[!is.na(camp[,"Count"]),]
camp <- camp[!is.na(camp[,"Count"]),]
m <- ggplot(camp, aes(x=X..Times.Opened))
m + geom_histogram()
?table
names(camp)
table(camp$X..Times.Opened, camp$Type)
table(camp$X..Times.Opened)
table(camp$X..Times.Opened, camp$Type)
names(camp)
table(camp$Wann.Gen, camp$Type)
table(camp[camp$Genervt == 1,]$Wann.Gen, camp[camp$Genervt == 1,]$$Type)
table(camp[camp$Genervt == 1,]$Wann.Gen, camp[camp$Genervt == 1,]$Type)
head(camp)
str(camp)
m <- ggplot(camp, aes(x=X..Times.Opened)) + geom_histogram()
m
table(camp[camp$Genervt == "Ok",]$Wann.Gen, camp[camp$Genervt == "Ok",]$Type)
table(camp[camp$Genervt == "Gen",]$Wann.Gen, camp[camp$Genervt == "Gen",]$Type)
table(camp[camp$Genervt == "Ok",]$Rehienfolge, camp[camp$Genervt == "Ok",]$Type)
str(camp)
table(camp[camp$Genervt == "Ok",]$Rehienfolge, camp[camp$Genervt == "Ok",]$Type)
camp[camp$Genervt == "Ok",]$Rehienfolge
camp[camp$Genervt == "Ok",]$Rehienfolge
camp$Genervt
camp$Genervt == "Ok"
camp[camp$Genervt == "Ok",]
table(camp[camp$Genervt == "Ok",]$Reihenfolge, camp[camp$Genervt == "Ok",]$Type)
file <- "C:\\Users\\mmorelli\\Google Drive\\Statistical Learning Stanford\\Week10\\10.R.RData"
load(file)
head(x)
tot <- rbind(x, x.test)
pca.out=prcomp(tot, scale=TRUE)
pca.out$sdev
redux <- pca.out$x[1,c(1,5)]
dim(redux)
summary(redux)
dimension(redux)
str(redux)
dim.data.frame(redux)
length(redux)
nrow(redux)
redux
redux <- pca.out$x[,c(1,5)]
redux <- pca.out$x[,c(1,5)]
dim(redux)
file <- "C:\\Users\\mmorelli\\Google Drive\\Statistical Learning Stanford\\Week10\\10.R.RData"
load(file)
head(x)
tot <- rbind(x, x.test)
pca.out=prcomp(tot, scale=TRUE)
pca.out$sdev
redux <- pca.out$x[,c(1,5)]
dim(redux)
x.pca  <-predict(pca.out, x)[,c(1:5)]
file <- "C:\\Users\\mmorelli\\Google Drive\\Statistical Learning Stanford\\Week10\\10.R.RData"
load(file)
tot <- rbind(x, x.test)
pca.out=prcomp(tot, scale=TRUE)
file <- "C:\\Users\\mmorelli\\Google Drive\\Statistical Learning Stanford\\Week10\\10.R.RData"
load(file)
tot <- rbind(x, x.test)
pca.out=prcomp(tot, scale=TRUE)
pca.out$sdev
x.pca  <-predict(pca.out, x)[,c(1:5)]
Group<-c(rep("Frank",times=6),rep("Greg",times=11),rep("Stacy",times=3),rep("Nancy",times=10))
X<-c(4,5,3,5,7,4,8,23,4,7,5,2,8,5,8,3,6,5,4,6,8,9,2,5,8,3,6,3,3,4)
Y<-c(7,9,3,6,4,8,7,8,6,3,2,3,6,7,4,6,8,9,5,7,8,9,6,5,4,6,7,8,3,6)
df<-data.frame(Group,as.numeric(X),as.numeric(Y))
Group
df
library(geometry)
install.package(geometry)
install.packages("geometry")
library(geometry)
convhulln(Frank.frame, option="FA")$vol
Frank.frame<-cbind(df$X[df$Group=="Frank"],df$Y[df$Group=="Frank"])
convhulln(Frank.frame, option="FA")$vol
setwd("C:\\Users\\mmorelli\\Google Drive\\MITx 15 071x The Analytics Edge\\Week 02")
# VIDEO 2
# Read in data
baseball = read.csv("baseball.csv")
str(baseball)
# Subset to only include moneyball years
moneyball = subset(baseball, Year < 2002)
str(moneyball)
# Compute Run Difference
moneyball$RD = moneyball$RS - moneyball$RA
# run scored - run allowed
str(moneyball)
# Scatterplot to check for linear relationship
plot(moneyball$RD, moneyball$W)
# Regression model to predict wins
WinsReg = lm(W ~ RD, data=moneyball)
summary(WinsReg)
q <- data.frame(RD=c(99, 100))
res <- predict(WinsReg, newData = data.frame(RD=c(99.0)))
summary(WinsReg)
coef(WinsReg)
coef(WinsReg)[0]
coef(WinsReg)$Intercept
str(coef(WinsReg))
coef(WinsReg)[1]
coef(WinsReg)[1]+ 99 * coef(WinsReg)[2]
# VIDEO 3
str(moneyball)
# Regression model to predict runs scored
RunsReg = lm(RS ~ OBP + SLG + BA, data=moneyball)
summary(RunsReg)
RunsReg = lm(RS ~ OBP + SLG, data=moneyball)
summary(RunsReg)
coef(RunsReg)
runs <- function(OBP, SLG){
coef(RunsReg)[0] +
coef(RunsReg)[1] * OBP +
coef(RunsReg)[2] * SLG
}
runs(0.311, 0.405)
runs <- function(OBP, SLG){
return coef(RunsReg)[0] +
coef(RunsReg)[1] * OBP +
coef(RunsReg)[2] * SLG
}
runs(0.311, 0.405)
a <- runs(0.311, 0.405)
a
runs <- function(OBP, SLG){
coef(RunsReg)[0] +
coef(RunsReg)[1] * OBP +
coef(RunsReg)[2] * SLG
}
a <- runs(0.311, 0.405)
a
a[1]
runs <- function(OBP, SLG){
coef(RunsReg)[1] +  coef(RunsReg)[2] * OBP +  coef(RunsReg)[3] * SLG
}
a <- runs(0.311, 0.405)
a[1]
RunsAll <- lm(RA ~ OOBP + OSLG, data=moneyball)
summary(RunsAll)
runsAll <- function(OOBP, OSLG){
coef(RunsAll)[1] +  coef(RunsAll)[2] * OBP +  coef(RunsAll)[3] * SLG
}
runsAll(0.297, 0.37)
runsAll <- function(OOBP, OSLG){
coef(RunsAll)[1] +  coef(RunsAll)[2] * OOBP +  coef(RunsAll)[3] * OSLG
}
runsAll(0.297, 0.37)
a[1]
runs(0.311, 0.405)
Eric Chavez <- runs	(0.338, 	0.540 ) /	1400
EricChavez <- runs(0.338, 	0.540 ) /	1400
EricChavez <- runs(0.338, 	0.540 ) /	1400
JeremyGiambi 	<- runs(0.391, 	0.450 ) /	 	1065
FrankMenechino 	<- runs(0.369, 	0.374 ) /	 	295
GregMyers 	<- runs(0.313, 	0.447 ) /	 	800
CarlosPena 	<- runs(0.361, 	0.500 ) /	 	300
EricChavez      <- runs(0.338, 	0.540 )
JeremyGiambi 	  <- runs(0.391, 	0.450 )
FrankMenechino 	<- runs(0.369, 	0.374 )
GregMyers 	    <- runs(0.313, 	0.447 )
CarlosPena     	<- runs(0.361, 	0.500 )
EricChavez
JeremyGiambi
FrankMenechino
GregMyers
CarlosPena
c(1,2,3,3,4,4,4,4,5,5)
teamRank = c(1,2,3,3,4,4,4,4,5,5)
setwd("C:\\Users\\mmorelli\\Google Drive\\MITx 15 071x The Analytics Edge\\Week 02")
# VIDEO 1
# Read in the data
NBA = read.csv("NBA_train.csv")
str(NBA)
# VIDEO 2
# How many wins to make the playoffs?
table(NBA$W, NBA$Playoffs)
# Compute Points Difference
NBA$PTSdiff = NBA$PTS - NBA$oppPTS
# Check for linear relationship
plot(NBA$PTSdiff, NBA$W)
plot(NBA$PTS , NBA$W)
# Linear regression model for wins
WinsReg = lm(W ~ PTSdiff, data=NBA)
summary(WinsReg)
# VIDEO 3
# Linear regression model for points scored
PointsReg = lm(PTS ~ X2PA + X3PA + FTA + AST + ORB + DRB + TOV + STL + BLK, data=NBA)
summary(PointsReg)
setwd("C:\\Users\\mmorelli\\Google Drive\\MITx 15 071x The Analytics Edge\\Week 02")
# VIDEO 2
# Read in data
baseball = read.csv("baseball.csv")
str(baseball)
# Subset to only include moneyball years
moneyball = subset(baseball, Year < 2002)
str(moneyball)
# Compute Run Difference
moneyball$RD = moneyball$RS - moneyball$RA
# run scored - run allowed
str(moneyball)
# Scatterplot to check for linear relationship
plot(moneyball$RD, moneyball$W)
# Regression model to predict wins
WinsReg = lm(W ~ RD, data=moneyball)
summary(WinsReg)
q <- data.frame(RD=c(99, 100))
res <- predict(WinsReg, newData = data.frame(RD=c(99.0)))
summary(WinsReg)
coef(WinsReg)[1]+ 99 * coef(WinsReg)[2]
# VIDEO 3
str(moneyball)
# Regression model to predict runs scored
RunsReg = lm(RS ~ OBP + SLG + BA, data=moneyball)
summary(RunsReg)
RunsReg = lm(RS ~ OBP + SLG, data=moneyball)
summary(RunsReg)
#--------------------
runs <- function(OBP, SLG){
coef(RunsReg)[1] +  coef(RunsReg)[2] * OBP +  coef(RunsReg)[3] * SLG
}
runs(0.311, 0.405)
RunsAll <- lm(RA ~ OOBP + OSLG, data=moneyball)
summary(RunsAll)
runsAll <- function(OOBP, OSLG){
coef(RunsAll)[1] +  coef(RunsAll)[2] * OOBP +  coef(RunsAll)[3] * OSLG
}
runsAll(0.297, 0.37)
#-----------------
EricChavez      <- runs(0.338, 	0.540 )
JeremyGiambi 	  <- runs(0.391, 	0.450 )
FrankMenechino 	<- runs(0.369, 	0.374 )
GregMyers 	    <- runs(0.313, 	0.447 )
CarlosPena     	<- runs(0.361, 	0.500 )
EricChavez
JeremyGiambi
FrankMenechino
GregMyers
CarlosPena
Win12 <- c(94, 88, 95, 88, 93, 94, 98, 97, 93, 94)
Win12 <- c(94, 88, 95, 88, 93, 94, 98, 97, 93, 94)
Win13 <- c(97, 97, 92, 93, 92, 96, 94, 96, 92, 90)
cor(teamRank, Win12)
teamRank = c(1,2,3,3,4,4,4,4,5,5)
Win12 <- c(94, 88, 95, 88, 93, 94, 98, 97, 93, 94)
Win13 <- c(97, 97, 92, 93, 92, 96, 94, 96, 92, 90)
cor(teamRank, Win12)
cor(teamRank, Win13)
setwd("C:\\Users\\mmorelli\\Google Drive\\MITx 15 071x The Analytics Edge\\Week 02")
climate <- read.csv(climate_change.csv)
climate <- read.csv("climate_change.csv")
summary(climate)
str(climate)
train <- subset(climate, climate$Year <= 2006)
head(train)
tail(train)
test  <- subset(climate, climate$Year > 2006)
tail(test)
str(climate)
model1 <- lm(Temp ~ MEI + CO2 + CH4 + N2O + CFC.11 + CFC.12 + TSI + Aerosols, data=climate)
summary(model1)
model1 <- lm(Temp ~ MEI + CO2 + CH4 + N2O + CFC.11 + CFC.12 + TSI + Aerosols, data=train)
summary(model1)
correlation(train)
cor(train)
corr(train[, "MEI", "CO2", "CH4", "N2O", "CFC.11", "CFC.12", "TSI", "Aerosols"])
cor(train[, "MEI", "CO2", "CH4", "N2O", "CFC.11", "CFC.12", "TSI", "Aerosols"])
cor(train[, c("MEI", "CO2", "CH4", "N2O", "CFC.11", "CFC.12", "TSI", "Aerosols")])
model2 <- lm(Temp ~ MEI + TSI + Aerosols + N20, data=train)
model2 <- lm(Temp ~ MEI + TSI + Aerosols + N20, data=train)
model2 <- lm(Temp ~ MEI + TSI + Aerosols + N2O, data=train)
summary(model2)
step(model1)
model3 <- step(model1)
summary(model3)
summary(model1)
summary(model3)
testres <- predict(model3, newdata= test)
testres
SSE = sum((testres - test$Temp)^2)
SST = sum((mean(Train$Temp) - test$Temp)^2)
SST = sum((mean(train$Temp) - test$Temp)^2)
R2 = 1 - SSE/SST
R2
setwd("C:\\Users\\mmorelli\\Google Drive\\MITx 15 071x The Analytics Edge\\Week 02")
ptrain <- read.csv("pisa2009train.csv")
ptest <-read.csv("pisa2009test.csv")
?tapply
tapply(ptrain$grade, ptrain$male, mean)
tapply(ptrain$readingScore, ptrain$male, mean)
summary(ptrain)
pisaTrain = na.omit(ptrain)
pisaTest = na.omit(ptest)
str(pisaTest)
pisaTrain$raceeth = relevel(pisaTrain$raceeth, "White")
pisaTest$raceeth = relevel(pisaTest$raceeth, "White")
lmScore <- lm(readingScore ~ .  ,data=pisaTrain)
summary(lmScore)
predict(lmScore)
rmse(lmScore$readingScore, predict(lmScore))
include(metrics)
require(metrics)
install.packages("metrics")
install.packages("Metrics")
require(metrics)
require(Metrics)
rmse(lmScore$readingScore, predict(lmScore))
lmScore$readingScore
rmse(pisaTrain$readingScore, predict(lmScore))
summary(lmScore)
predtest <- predict(lmScore, newdata=pisaTest)
SSE = sum((predtest - pisaTest$readingScore)^2)
SST = sum((mean(pisaTrain$readingScore) - pisaTest$readingScore)^2)
R2 = 1 - SSE/SST
R2
range(predtest)
r <- range(predtest)
r[2] -r[1]
SSE = sum((predtest - pisaTest$readingScore)^2)
SSE
R2
RMSE <- sqrt(sse/numrow(pisaTest))
RMSE <- sqrt(SSE/numrow(pisaTest))
RMSE <- sqrt(SSE/rownum(pisaTest))
RMSE <- sqrt(SSE/nrow(pisaTest))
RMSE
sum((mean(pisaTrain$readingScore)
)
)
mean(pisaTrain$readingScore)
SST = sum((mean(pisaTrain$readingScore) - pisaTest$readingScore)^2)
SST
R2
FluTrain <- read.csv("FluTrain.csv")
head(FluTrain)
?order
FluTrain[order(FluTrain$ILI)]
FluTrain[order(FluTrain$ILI),]
tail(FluTrain[order(FluTrain$ILI),])
tail(FluTrain[order(FluTrain$Queries),])
hist(FluTrain$ILI)
plot(FluTrain$Queries, log(FluTrain$ILI))
FluTrend1 <- lm(log(ILI) ~ Queries, data = FluTrain)
summary(FluTrend1)
cor(log(ILI),Queries)
cor(log(ILI), FluTrain$Queries)
cor(log(FluTrain$ILI), FluTrain$Queries)
FluTest <- read.csv("FluTest.csv")
FluTrain <- read.csv("FluTrain.csv")
PredTest1 = exp(predict(FluTrend1, newdata=FluTest))
?which
head(PredTest1)
FluTest$Week
which(FluTest$Week = "2012-12-02 - 2012-12-08")
which(FluTest$Week == "2012-12-02 - 2012-12-08")
which(FluTest$Week == "2012-03-11 - 2012-03-18")
which(FluTest$Week == "2012-03-11 - 2012-03-17")
PredTest1[which(FluTest$Week == "2012-03-11 - 2012-03-17")]
pt <- PredTest1[which(FluTest$Week == "2012-03-11 - 2012-03-17")]
head(FluTest)
ot <- FluTest[which(FluTest$Week == "2012-03-11 - 2012-03-17"),"ILI"]
(ot - pt)/ot
SSEt <- sum((PredTest1 - FluTest$ILI)^2)
head(PredTest1)
RMSEt <- sqrt(SSEt / nrow(PredTest1))
RMSEt <- sqrt(SSEt / nrow(FluTest))
RMSEt
install.packages("zoo")
library(zoo)
ILILag2 = lag(zoo(FluTrain$ILI), -2, na.pad=TRUE)
FluTrain$ILILag2 = coredata(ILILag2)
summary(ILILag2)
plot(log(FluTrain$ILI), log(ILILag2))
FluTrend2 <-  lm(log(ILI) ~ Queries+ log(ILILag2) , data = FluTrain)
summary(FluTrend2)
ILILag2 = lag(zoo(FluTest$ILI), -2, na.pad=TRUE)
FluTest$ILILag2 = coredata(ILILag2)
summary(ILILag2)
tail(FluTrain)
FluTrain[-2,"ILILag2"]
FluTrain$ILILag2[-2]
FluTrain$ILILag2[1]
FluTrain$ILILag2[2]
FluTrain$ILILag2[nrow(FluTrain)]
tail(FluTrain)
FluTrain$ILILag2[nrow(FluTrain)-1]
FluTrain$ILILag2[nrow(FluTrain)-1]
FluTrain$ILILag2[nrow(FluTrain)]
FluTrain$ILI[nrow(FluTrain)-1]
FluTrain$ILI[nrow(FluTrain)]
FluTest$ILILag2[1] <- FluTrain$ILI[nrow(FluTrain)-1]
FluTest$ILILag2[2] <- FluTrain$ILI[nrow(FluTrain)]
PredTest2 = exp(predict(FluTrend2, newdata=FluTest))
summary(PredTest2)
SSEt2 <- sum((PredTest2 - FluTest$ILI)^2)
RMSEt2 <- sqrt(SSEt2 / nrow(FluTest))
RMSEt2
setwd("C:\\Users\\mmorelli\\Google Drive\\MITx 15 071x The Analytics Edge\\Week 02")
climate <- read.csv("climate_change.csv")
str(climate)
train <- subset(climate, climate$Year <= 2006)
test  <- subset(climate, climate$Year > 2006)
tail(test)
model1 <- lm(Temp ~ MEI + CO2 + CH4 + N2O + CFC.11 + CFC.12 + TSI + Aerosols, data=train)
summary(model1)
# correlation
cor(train[, c("MEI", "CO2", "CH4", "N2O", "CFC.11", "CFC.12", "TSI", "Aerosols")])
model2 <- lm(Temp ~ MEI + TSI + Aerosols + N2O, data=train)
summary(model2)
model3 <- step(model1)
summary(model3)
# predictions
testres <- predict(model3, newdata= test)
# Compute out-of-sample R^2
SSE = sum((testres - test$Temp)^2)
SST = sum((mean(train$Temp) - test$Temp)^2)
R2 = 1 - SSE/SST
R2
summary(model3)
