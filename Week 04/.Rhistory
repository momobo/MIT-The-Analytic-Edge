result <- array(1:TRY)
for(i in 1:TRY){
train <- get_N(TRAINN)
--  ffit<-svm(y~.,data=train)
ffit <- glm(y~.,data=train, family=binomial)
test <- get_N(TESTN)
testmy = test[,-1]
predicted <- predict(ffit, newdata=testmy)
result[i] <-  sum(ifelse(predicted > 0.5,1,0) == test$y) / TESTN
}
1-mean(result)
sd(result)
result
result <- array(TRY)
result
a[1] <- 1
a <- array()
a[1] <- 1
a
result <- array()
for(i in 1:TRY){
train <- get_N(TRAINN)
--  ffit<-svm(y~.,data=train)
ffit <- glm(y~.,data=train, family=binomial)
test <- get_N(TESTN)
testmy = test[,-1]
predicted <- predict(ffit, newdata=testmy)
result[i] <-  sum(ifelse(predicted > 0.5,1,0) == test$y) / TESTN
}
train <- get_N(TRAINN)
--  ffit<-svm(y~.,data=train)
ffit <- glm(y~.,data=train, family=binomial)
ffit <- glm(y~.,data=train, family=binomial())
result <- array()
for(i in 1:TRY){
train <- get_N(TRAINN)
--  ffit<-svm(y~.,data=train)
ffit <- glm(y~.,data=train, family=binomial())
test <- get_N(TESTN)
testmy = test[,-1]
predicted <- predict(ffit, newdata=testmy)
result[i] <-  sum(ifelse(predicted > 0.5,1,0) == test$y) / TESTN
}
train <- get_N(TRAINN)
--  ffit<-svm(y~.,data=train)
ffit <- glm(y~.,data=train, family=binomial
result <- array()
for(i in 1:TRY){
train <- get_N(TRAINN)
#  ffit<-svm(y~.,data=train)
ffit <- glm(y~.,data=train, family=binomial)
test <- get_N(TESTN)
testmy = test[,-1]
predicted <- predict(ffit, newdata=testmy)
result[i] <-  sum(ifelse(predicted > 0.5,1,0) == test$y) / TESTN
}
1-mean(result)
sd(result)
dimnames(USArrests)
apply(USArrests,2,mean)
apply(USArrests,2, var)
pca.out=prcomp(USArrests, scale=TRUE)
pca.out
names(pca.out)
biplot(pca.out, scale=0)
set.seed(101)
x=matrix(rnorm(100*2),100,2)
xmean=matrix(rnorm(8,sd=4),4,2)
which=sample(1:4,100,replace=TRUE)
x=x+xmean[which,]
plot(x,col=which,pch=19)
km.out=kmeans(x,4,nstart=15)
km.out
plot(x,col=km.out$cluster,cex=2,pch=1,lwd=2)
points(x,col=which,pch=19)
points(x,col=c(4,3,2,1)[which],pch=19)
file <- "C:\\Users\\mmorelli\\Google Drive\\Statistical Learning Stanford\\Week10\\10.R.RData"
load(file)
file <- "C:\\Users\\mmorelli\\Google Drive\\Statistical Learning Stanford\\Week10\\10.R.RData"
load(file)
head(x)
pca.out=prcomp(x, scale=TRUE)
tot <- rbind(x, x.test)
pca.out=prcomp(tot, scale=TRUE)
names(x)
names(x.test)
dimnames(USArrests)
apply(USArrests,2,mean)
apply(USArrests,2, var)
pca.out=prcomp(USArrests, scale=TRUE)
pca.out
names(pca.out)
biplot(pca.out, scale=0)
pca.out=prcomp(tot, scale=TRUE)
?prcomp
pca.out$sdev
pca.out$rotation
pca.out$x
summary(pca.out)
redux <- pca.out$x[1,c(1,5)]
head(redux)
redux <- pca.out$x[1,c(1,5)]
head(redux)
pca.out$sdev
str(pca.out)
str(pca.out)$x
str(pca.out)$x
redux <- pca.out$x[1,c(1,5)]
pca.5 <- pca.out$x[1,c(1,5)]
pca.5 <- pca.out$x[1,c(1:5)]
redux
pca.5 <- pca.out$x[,c(1:5)]
head(pca.5)
pca.5 <- as_data_frame(pca.out$x[,c(1:5)])
pca.5 <- as.data.frame(pca.out$x[,c(1:5)])
reconstructedData<-predict(pca.out, x)
x.pca <-predict(pca.out, x)
head x.pca
x.pca <-predict(pca.out, x)
head(x.pca)
x.pca <-predict(pca.out, x)[,c(1:5)]
head(x.pca)
xy.pca <- cbind(x.pca, y)
head(xy.pca)
fit <- lm(y~., data=xy.pca)
xy.pca <- as.data.frame(cbind(x.pca, y))
head(xy.pca)
fit <- lm(y~., data=xy.pca)
summary(fit)
summary(fit)
x.test.pca  <- predict(pca.out, x.test)[,c(1:5)]
xy.test.pca <- as.data.frame(cbind(x.test.pca, y.test))
y.pred <- predict(fit, xy.test.pca)
se <- (y.pred- y.test)^2
sum(se)/1000
mean(se)
train <- as.data.frame(cbind(x, y))
train <- as.data.frame(cbind(x, y))
test  <- as.data.frame(cbind(x.test, y.test))
fit.all <- lm(y~., train)
y.all.pred <- predict(fit.all, test)
se.all <- (y.all.pred -y.test)^2
mean(se.all)
load(file)
train <- as.data.frame(cbind(x, y))
test  <- as.data.frame(cbind(x.test, y.test))
fit.all <- lm(y~., train)
y.all.pred <- predict(fit.all, test)
se.all <- (y.all.pred -y.test)^2
mean(se.all)
file <- "C:\\Users\\mmorelli\\Google Drive\\Statistical Learning Stanford\\Week10\\10.R.RData"
load(file)
train <- as.data.frame(cbind(x, y))
test  <- as.data.frame(cbind(x.test, y.test))
fit.all <- lm(y~., train)
y.all.pred <- predict(fit.all, test)
se.all <- (y.all.pred -y.test)^2
mean(se.all)
?lm
fit.all
summary(fit.all)
mean(se.all)
file <- "C:\\Users\\mmorelli\\Documents\\work\\Campagne\\10.R.RData\\campagne.csv"
camp <- load.csv(file)
?load
camp <- read.csv(file)
file <- "C:\\Users\\mmorelli\\Documents\\work\\Campagne\\campagne.csv"
camp <- read.csv(file)
head(camp)
names(camp)
?read.csv
camp <- read.csv(file, sep=";")
head(camp)
names(camp)
unique(Subject)
unique(camp$Subject)
names(camp)
unique(camp$Email.Template.Name)
camp[leistung$Email.Template.Name %in% c("2016-01 Contacts Compliance", "2016-01 Mailing Compliance", "2016-01 Leads Compliance"),]$template <- "Compliance"
camp[leistung$Email.Template.Name %in% c("2016-01 Contacts Schadensvermeidung", "2016-01 Leads Schadensvermeidung", "2016-01 Mailing Schadensvermeidung"),]$template <- "Schadensverm."
camp[leistung$Email.Template.Name %in% c("2016-01 Contacts Zeitoptimierung", "2016-01 Mailing Zeitoptimierung", "2016-01 Leads Zeitoptimierung"),]$template <- "Zeitoptim"
camp[leistung$Email.Template.Name %in% c("2016-01 Contacts _berblick", "2016-01 Mailing _berblick", "2016-01 Leads _berblick"),]$template <- ""
camp[leistung$Email.Template.Name %in% c("2016-01 Contacts Planungssicherheit", "2016-01 Mailing Planungssicherheit", "2016-01 Leads Planungssicherheit"),]$template <- ""
camp[camp$Email.Template.Name %in% c("2016-01 Contacts Compliance", "2016-01 Mailing Compliance", "2016-01 Leads Compliance"),]$template <- "Compliance"
camp[camp$Email.Template.Name %in% c("2016-01 Contacts Compliance", "2016-01 Mailing Compliance", "2016-01 Leads Compliance"),]
names(camp)
histogram(camp$OpenedNum)
library(ggplot2)
m <- ggplot(camp, aes(x=OpenedNum))
m + geom_histogram()
str(camp)
m <- ggplot(camp, aes(x=X..Times.Opened))
m + geom_histogram()
m <- ggplot(camp, aes(x=Pattern))
m + geom_histogram()
m <- ggplot(camp, aes(x=X..Times.Opened))
m + geom_histogram()
tail(camp)
camp[is.na(camp[,"Count"]),]
camp[!is.na(camp[,"Count"]),]
camp <- camp[!is.na(camp[,"Count"]),]
m <- ggplot(camp, aes(x=X..Times.Opened))
m + geom_histogram()
?table
names(camp)
table(camp$X..Times.Opened, camp$Type)
table(camp$X..Times.Opened)
table(camp$X..Times.Opened, camp$Type)
names(camp)
table(camp$Wann.Gen, camp$Type)
table(camp[camp$Genervt == 1,]$Wann.Gen, camp[camp$Genervt == 1,]$$Type)
table(camp[camp$Genervt == 1,]$Wann.Gen, camp[camp$Genervt == 1,]$Type)
head(camp)
str(camp)
m <- ggplot(camp, aes(x=X..Times.Opened)) + geom_histogram()
m
table(camp[camp$Genervt == "Ok",]$Wann.Gen, camp[camp$Genervt == "Ok",]$Type)
table(camp[camp$Genervt == "Gen",]$Wann.Gen, camp[camp$Genervt == "Gen",]$Type)
table(camp[camp$Genervt == "Ok",]$Rehienfolge, camp[camp$Genervt == "Ok",]$Type)
str(camp)
table(camp[camp$Genervt == "Ok",]$Rehienfolge, camp[camp$Genervt == "Ok",]$Type)
camp[camp$Genervt == "Ok",]$Rehienfolge
camp[camp$Genervt == "Ok",]$Rehienfolge
camp$Genervt
camp$Genervt == "Ok"
camp[camp$Genervt == "Ok",]
table(camp[camp$Genervt == "Ok",]$Reihenfolge, camp[camp$Genervt == "Ok",]$Type)
file <- "C:\\Users\\mmorelli\\Google Drive\\Statistical Learning Stanford\\Week10\\10.R.RData"
load(file)
head(x)
tot <- rbind(x, x.test)
pca.out=prcomp(tot, scale=TRUE)
pca.out$sdev
redux <- pca.out$x[1,c(1,5)]
dim(redux)
summary(redux)
dimension(redux)
str(redux)
dim.data.frame(redux)
length(redux)
nrow(redux)
redux
redux <- pca.out$x[,c(1,5)]
redux <- pca.out$x[,c(1,5)]
dim(redux)
file <- "C:\\Users\\mmorelli\\Google Drive\\Statistical Learning Stanford\\Week10\\10.R.RData"
load(file)
head(x)
tot <- rbind(x, x.test)
pca.out=prcomp(tot, scale=TRUE)
pca.out$sdev
redux <- pca.out$x[,c(1,5)]
dim(redux)
x.pca  <-predict(pca.out, x)[,c(1:5)]
file <- "C:\\Users\\mmorelli\\Google Drive\\Statistical Learning Stanford\\Week10\\10.R.RData"
load(file)
tot <- rbind(x, x.test)
pca.out=prcomp(tot, scale=TRUE)
file <- "C:\\Users\\mmorelli\\Google Drive\\Statistical Learning Stanford\\Week10\\10.R.RData"
load(file)
tot <- rbind(x, x.test)
pca.out=prcomp(tot, scale=TRUE)
pca.out$sdev
x.pca  <-predict(pca.out, x)[,c(1:5)]
Group<-c(rep("Frank",times=6),rep("Greg",times=11),rep("Stacy",times=3),rep("Nancy",times=10))
X<-c(4,5,3,5,7,4,8,23,4,7,5,2,8,5,8,3,6,5,4,6,8,9,2,5,8,3,6,3,3,4)
Y<-c(7,9,3,6,4,8,7,8,6,3,2,3,6,7,4,6,8,9,5,7,8,9,6,5,4,6,7,8,3,6)
df<-data.frame(Group,as.numeric(X),as.numeric(Y))
Group
df
library(geometry)
install.package(geometry)
install.packages("geometry")
library(geometry)
convhulln(Frank.frame, option="FA")$vol
Frank.frame<-cbind(df$X[df$Group=="Frank"],df$Y[df$Group=="Frank"])
convhulln(Frank.frame, option="FA")$vol
setwd("C:\\Users\\mmorelli\\Google Drive\\MITx 15 071x The Analytics Edge\\Week 04")
gerber <- read.csv("gerber.csv")
str(gerber)
mean(gerber$voting)
mean(gerber[gerber$civicduty ==1,"voting"])
mean(gerber[gerber$hawthorne ==1,"voting"])
mean(gerber[gerber$self ==1,"voting"])
mean(gerber[gerber$neighbors==1,"voting"])
model1 <- glm(voting ~ civicduty + hawthorne + self + neighbors, data=gerber, family=binomial)
summary(model1)
TestPrediction = predict(model1, type="response")
table(gerber$voting , TestPrediction >= 0.3)
(134513 + 51966)/nrow(gerber)
table(gerber$voting , TestPrediction >= 0.5)
235388/nrow(gerber)
ROCRpred = prediction(TestPrediction, gerber$voting)
as.numeric(performance(ROCRpred, "auc")@y.values)
# TREES
CARTmodel = rpart(voting ~ civicduty + hawthorne + self + neighbors, data=gerber)
prp(CARTmodel)
CARTmodel2 = rpart(voting ~ civicduty + hawthorne + self + neighbors, data=gerber, cp=0.0)
prp(CARTmodel2)
CARTmodel3 = rpart(voting ~ civicduty + hawthorne + self + neighbors+ sex, data=gerber, cp=0.0)
library(caTools)
library(rpart)
library(rpart.plot)
library(caTools)
library(ROCR)
TestPrediction = predict(model1, type="response")
table(gerber$voting , TestPrediction >= 0.3)
(134513 + 51966)/nrow(gerber)
table(gerber$voting , TestPrediction >= 0.5)
235388/nrow(gerber)
ROCRpred = prediction(TestPrediction, gerber$voting)
as.numeric(performance(ROCRpred, "auc")@y.values)
# TREES
CARTmodel = rpart(voting ~ civicduty + hawthorne + self + neighbors, data=gerber)
prp(CARTmodel)
CARTmodel2 = rpart(voting ~ civicduty + hawthorne + self + neighbors, data=gerber, cp=0.0)
prp(CARTmodel2)
CARTmodel3 = rpart(voting ~ civicduty + hawthorne + self + neighbors+ sex, data=gerber, cp=0.0)
prp(CARTmodel3)
CartModel4 = rpart(voting ~ control, data=gerber, cp=0.0)
prp(CARTmodel4)
prp(CartModel4)
CartModel5 = rpart(voting ~ control + sex, data=gerber, cp=0.0)
prp(CartModel5)
Test5Prediction = predict(CartModel5, type="response")
Test5Prediction = predict(CartModel5, type="class")
Test5Prediction = predict(CartModel5, type="vector")
Test5Prediction
Test5Prediction = predict(CartModel5, newdata = gerber, type = "class")
CartModel5 = rpart(voting ~ control + sex, data=gerber, cp=0.0)
Test5Prediction = predict(CartModel5, newdata = gerber, type = "class")
Test5Prediction = predict(CartModel5, type="vector")
Test5Prediction
prp(CartModel5, digit=6)
prp(CartModel4, digit=6)
abs(0.34 - 0.296638)
prp(CartModel5, digit=6)
wc <- 0.302795
mc <- 0.290456
wn <- 0.345818
mn <- 0.334176
abs(wc-wn)
abs(mc-mn)
abs(wc-wn) - abs(mc-mn)
model2 <- glm(voting ~ sex+control, data=gerber, family=binomial)
summary(model2)
Possibilities = data.frame(sex=c(0,0,1,1),control=c(0,1,0,1))
predict(model2, newdata=Possibilities, type="response")
wclog <- 0.2908065
abs(wc -wclog)
prp(CartModel5, digit=6)
wc
wclog
wc -wclog
LogModel2 = glm(voting ~ sex + control + sex:control, data=gerber, family="binomial")
summary(LogModel2)
predict(LogModel2, newdata=Possibilities, type="response")
mc <- 0.302795
wc <- 0.290456
mn <- 0.345818
wn <- 0.334176
abs(wc-wn) - abs(mc-mn)
abs(wc -wclog)
predict(LogModel2, newdata=Possibilities, type="response")
wclog2 <- 0.2904558
abs(wc -wclog2)
ABPR <- read.csv("ABPR.csv")
letter <- read.csv("letters_ABPR.csv")
letters <- read.csv("letters_ABPR.csv")
rm(letter)
str(letters)
letters$isB = as.factor(letters$letter == "B")
set.seed(1000)
spl = sample.split(letters$letter, SplitRatio = 0.5)
train = subset(letters, spl==TRUE)
test  = subset(letters, spl==FALSE)
set.seed(1000)
spl = sample.split(letters$letter, SplitRatio = 0.5)
train = subset(letters, spl==TRUE)
test  = subset(letters, spl==FALSE)
test$isB == F
sum(test$isB == F)/nrow(test)
CARTb = rpart(isB ~ . - letter, data=train, method="class")
PredictTest = predict(CARTb, newdata = test, type = "class")
table(test$isB, PredictTest)
(1114 + 351 )/nrow(test)
set.seed(1000)
CartBForest = randomForest(isB ~ . - letter, data=train)
library(randomForest)
set.seed(1000)
CartBForest = randomForest(isB ~ . - letter, data=train)
PredictTest = predict(CartBForest, newdata = test, type = "class")
table(test$isB, PredictTest)
(1164 + 374 )/nrow(test)
letters$letter = as.factor( letters$letter )
set.seed(2000)
spl = sample.split(letters$letter, SplitRatio = 0.5)
train = subset(letters, spl==TRUE)
test  = subset(letters, spl==FALSE)
sum(test$isB == F)/nrow(test)
table(letters$letter)
sum(803)/nrow(test)
table(test$letter)
401/nrow(test)
CARTletter = rpart(letter ~ . - isB, data=train, method="class")
PredictTest = predict(CARTletter, newdata = test, type = "class")
table(test$letter, PredictTest)
(348 + 318 + 263 + 340 )/nrow(test)
(348 + 318 + 363 + 340 )/nrow(test)
set.seed(1000)
CARTlForest = randomForest(letter ~ . - isB, data=train, method="class")
PredictTest = predict(CARTlForest, newdata = test, type = "class")
table(test$letter, PredictTest)
(390 + 380 + 393 + 364 )/nrow(test)
head(letters)
setwd("C:\\Users\\mmorelli\\Google Drive\\MITx 15 071x The Analytics Edge\\Week 04")
census <- read.csv("census.csv")
str(census)
spl = sample.split(census$over50k, SplitRatio = 0.6)
train = subset(letters, spl==TRUE)
test  = subset(letters, spl==FALSE)
spl = sample.split(census$over50k, SplitRatio = 0.6)
set.seed(2000)
spl = sample.split(census$over50k, SplitRatio = 0.6)
train = subset(census, spl==TRUE)
test  = subset(census, spl==FALSE)
table(test$over50)
model1 <- glm(over50 ~ ., data=test, family=binomial)
summary(model1)
table(test$over50k)
model1 <- glm(over50k ~ ., data=test, family=binomial)
summary(model1)
model1 <- glm(over50k ~ ., data=train, family=binomial)
summary(model1)
TestPrediction = predict(model1, newdata=test, type="response")
table(census$over50k , TestPrediction >= 0.5)
table(test$over50k , TestPrediction >= 0.5)
Accuracy <- (9051+1888)/nrow(test)
Accuracy
table(test$over50k)
9713/nrow(test)
library(ROCR)
ROCRpred = prediction(TestPrediction, test$over50k)
as.numeric(performance(ROCRpred, "auc")@y.values)
CART = rpart(over50k ~ ., data=train, method="class")
prp(CART)
PredictTest = predict(CART, newdata = test, type = "class")
table(test$over50k, PredictTest)
(9243 + 1596 )/nrow(test)
ROCRpred = prediction(PredictTest, test$over50k)
PredictTest
TestPrediction
PredictTest = predict(CART, newdata = test)
PredictTest
ROCRpred = prediction(PredictTest[2], test$over50k)
PredictTest[2]
PredictTest = predict(CART, newdata = test)
PredictTest
ROCRpred = prediction(PredictTest[,2], test$over50k)
as.numeric(performance(ROCRpred, "auc")@y.values)
plot(ROCRpred)
ROCRpred = prediction(PredictTest, test$over50k)
PredictTest
ROCRpred = prediction(PredictTest[,2], test$over50k)
ROCRperf = performance(ROCRpred, "tpr", "fpr")
plot(ROCRperf)
PredictTest = predict(CART, newdata = test)
ROCRpred = prediction(PredictTest[,2], test$over50k)
as.numeric(performance(ROCRpred, "auc")@y.values)
ROCRperf
set.seed(1)
trainSmall = train[sample(nrow(train), 2000), ]
library(randomForest)
PredictTest = predict(over50k ~ ., data=train, type = "class")
ModelForest = randomForest(over50k ~ ., data=train)
PredictTest = predict(ModelForest, newdata = test, type = "class")
table(test$over50k, PredictTest)
(9866 + 867 )/nrow(test)
set.seed(1)
ModelForest = randomForest(over50k ~ ., data=trainSmall)
PredictTest = predict(ModelForest, newdata = test, type = "class")
table(test$over50k, PredictTest)
(9586 + 1093 )/nrow(test)
vu = varUsed(ModelForest, count=TRUE)
vusorted = sort(vu, decreasing = FALSE, index.return = TRUE)
dotchart(vusorted$x, names(MODEL$forest$xlevels[vusorted$ix]))
dotchart(vusorted$x, names(ModelForest$forest$xlevels[vusorted$ix]))
varImpPlot(ModelForest)
library(caret)
library(e1071)
set.seed(2)
numFolds = trainControl( method = "cv", number = 10 )
cartGrid = expand.grid( .cp = seq(0.002,0.1,0.002))
# Perform the cross validation
train(over50k ~ ., data = trainSmall, method = "rpart", trControl = numFolds, tuneGrid = cartGrid )
set.seed(2)
numFolds = trainControl( method = "cv", number = 10 )
cartGrid = expand.grid( .cp = seq(0.002,0.1,0.002))
# Perform the cross validation
train(over50k ~ ., data = train, method = "rpart", trControl = numFolds, tuneGrid = cartGrid )
modelCART = rpart(over50k ~ ., data = train, method="class", cp = 0.02)
PredictCART = predict(modelCART, newdata = test, type = "class")
table(test$over50k, PredictCART)
(9243+1596)/nrow(test)
modelCART = rpart(over50k ~ ., data = train, method="class", cp = 0.002)
# Make predictions
PredictCART = predict(modelCART, newdata = test, type = "class")
table(test$over50k, PredictCART)
(9178+1838)/nrow(test)
prp(modelCART)
modelCART
summary(modelCART)
